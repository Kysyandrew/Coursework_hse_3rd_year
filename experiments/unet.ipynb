{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальный пайплайн обучения и теста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-27T11:54:38.802685Z",
     "iopub.status.busy": "2025-04-27T11:54:38.801973Z",
     "iopub.status.idle": "2025-04-27T11:54:50.244388Z",
     "shell.execute_reply": "2025-04-27T11:54:50.243381Z",
     "shell.execute_reply.started": "2025-04-27T11:54:38.802662Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install vesuvius\n",
    "!vesuvius.accept_terms --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T11:54:50.246520Z",
     "iopub.status.busy": "2025-04-27T11:54:50.246285Z",
     "iopub.status.idle": "2025-04-27T11:54:50.251906Z",
     "shell.execute_reply": "2025-04-27T11:54:50.251187Z",
     "shell.execute_reply.started": "2025-04-27T11:54:50.246494Z"
    }
   },
   "outputs": [],
   "source": [
    "import vesuvius\n",
    "from vesuvius import Volume\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T11:54:50.252991Z",
     "iopub.status.busy": "2025-04-27T11:54:50.252721Z",
     "iopub.status.idle": "2025-04-27T11:54:50.272479Z",
     "shell.execute_reply": "2025-04-27T11:54:50.271780Z",
     "shell.execute_reply.started": "2025-04-27T11:54:50.252968Z"
    }
   },
   "outputs": [],
   "source": [
    "class VolumetricDataset(Dataset):\n",
    "    def __init__(self, volume, label, tile_size, stride, validation_zone, valid=False):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with the volume and label.\n",
    "        \n",
    "        volume (np.ndarray): The volumetric image of shape (Z, Y, X).\n",
    "        label (np.ndarray): The 2D label of shape (Y, X).\n",
    "        tile_size (int): The size of the tiles to extract along the Y and X dimensions.\n",
    "        stride (int): The stride for extracting tiles along the Y and X dimensions.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.volume = volume\n",
    "        self.label = label\n",
    "        self.tile_size = tile_size\n",
    "        self.stride = stride\n",
    "        self.validation_zone = validation_zone\n",
    "        self.valid = valid\n",
    "        self.tiles, self.labels, self.corners = self.extract_tiles()\n",
    "\n",
    "    def extract_tiles(self):\n",
    "        \"\"\"\n",
    "        Extract 3D tiles from the volume and corresponding 2D labels.\n",
    "\n",
    "        Returns:\n",
    "            tiles (list): A list of 3D tiles.\n",
    "            labels (list): A list of 2D labels.\n",
    "        \"\"\"\n",
    "        Z, Y, X = self.volume.shape\n",
    "        tiles = []\n",
    "        labels = []\n",
    "        corners = []\n",
    "        # generate 3D tiles by moving along the Y and X axes\n",
    "        for y in range(0, Y - self.tile_size + 1, self.stride):\n",
    "            for x in range(0, X - self.tile_size + 1, self.stride):\n",
    "                if self.valid is False:\n",
    "                    if (y + self.tile_size < self.validation_zone[0]) or (y > self.validation_zone[1]):\n",
    "                        if (x + self.tile_size < self.validation_zone[2]) or (x > self.validation_zone[3]):\n",
    "                            tile = self.volume[:, y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            label_tile = self.label[y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            if np.sum(label_tile)/self.tile_size**2 > 0.05: # at least 5% of ink\n",
    "                                tiles.append(tile)\n",
    "                                labels.append(label_tile)\n",
    "                                corners.append([y,x])\n",
    "                else:\n",
    "                    if (y >= self.validation_zone[0]) and (y + self.tile_size <= self.validation_zone[1]):\n",
    "                        if (x >= self.validation_zone[2]) and (x + self.tile_size <= self.validation_zone[3]):\n",
    "                            tile = self.volume[:, y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            label_tile = self.label[y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            tiles.append(tile)\n",
    "                            labels.append(label_tile)\n",
    "                            corners.append([y,x])\n",
    "\n",
    "        return tiles, labels, corners\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tile = self.tiles[idx] \n",
    "        label = self.labels[idx]\n",
    "        corners = self.corners[idx]\n",
    "        \n",
    "        tile = torch.tensor(tile, dtype=torch.float32).unsqueeze(0)\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "        corners = torch.tensor(corners, dtype=torch.int).unsqueeze(0)\n",
    "        return tile, label, corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T11:54:50.274129Z",
     "iopub.status.busy": "2025-04-27T11:54:50.273934Z",
     "iopub.status.idle": "2025-04-27T11:54:50.295977Z",
     "shell.execute_reply": "2025-04-27T11:54:50.295252Z",
     "shell.execute_reply.started": "2025-04-27T11:54:50.274114Z"
    }
   },
   "outputs": [],
   "source": [
    "def fractal_dimension(binary):\n",
    "    '''\n",
    "    Calculate fractal dimension of binary image ln(N) / ln(1/r) using box counting method.\n",
    "    '''\n",
    "    device = binary.device\n",
    "    batch_size, blocks_num, height, width = binary.shape\n",
    "    min_dim = min(height, width)\n",
    "    # square sizes to use box counting method\n",
    "    scales = torch.tensor([1,2,4,6,8,10], device=device)\n",
    "    scales = torch.unique(scales)\n",
    "    scales = scales[scales <= min_dim]\n",
    "    counts = []\n",
    "\n",
    "    binary_flat = binary.view(-1, H, W)\n",
    "    cnt_flat = binary_flat.size(0)\n",
    "    for scale in scales:\n",
    "        if scale < 1:\n",
    "            continue\n",
    "\n",
    "        # add zero padding to use box counting method\n",
    "        pad_h = (scale - (H % scale)) % scale\n",
    "        pad_w = (scale - (W % scale)) % scale\n",
    "        padded_binary = F.pad(binary_flat, (0, pad_w, 0, pad_h), value=False)\n",
    "\n",
    "        # split image into small squares to use box counting method\n",
    "        unfolded = padded_binary.unfold(1, scale, scale).unfold(2, scale, scale)\n",
    "        count = unfolded.any(dim=-1).any(dim=-1).sum(dim=(1,2))\n",
    "        counts.append(count)\n",
    "\n",
    "    if len(counts) < 2:\n",
    "        return torch.zeros(batch_size, blocks_num, device=device)\n",
    "    \n",
    "    log_scales = torch.log(1 / scales.float() + 1e-8) # log(1/r)\n",
    "    log_counts = torch.log(torch.stack(counts, dim=1).float() + 1e-8) # log(N)\n",
    "\n",
    "    # here we prepare matricies to get the slope of the line that best fits the\n",
    "    # 2D points of the form (ln(N), ln(1/r))\n",
    "    # that way we will get fractal dimensions\n",
    "    X = torch.stack([log_scales, torch.ones_like(log_scales)], dim=1) \n",
    "    X = X.repeat(cnt_flat, 1, 1)\n",
    "    Y = log_counts.unsqueeze(-1)\n",
    "\n",
    "    # get the slope of the line that best fits the 2D points of the form (ln(N), ln(1/r)) \n",
    "    coeffs = torch.linalg.lstsq(X, Y).solution.squeeze(-1)\n",
    "\n",
    "    # FD is first coefficient (slope of the line)\n",
    "    fd = coeffs[..., 0]\n",
    "    return fd\n",
    "\n",
    "\n",
    "def calc_fractal_features(input_volume, windows = [2,4,8], thresholds=None, add_image_channel = False):\n",
    "    '''\n",
    "    Calculate fractal features of image with certain sizes of window \n",
    "    and certain thresholds to make image binary (binary = (image > image.mean() * threshold)).\n",
    "\n",
    "    Also we could add original image to those features.\n",
    "    '''\n",
    "    device = input_volume.device\n",
    "    batch_size, channels, z, y, x = input_volume.shape # channels = 1\n",
    "\n",
    "    volume = input_volume.view(batch_size*channels, z, y, x)\n",
    "\n",
    "    max_window_size = min(y, x) // 2\n",
    "    windows = torch.tensor(windows, device=device)\n",
    "    windows = windows[windows <= max_window_size]\n",
    "\n",
    "    if thresholds is None:\n",
    "        thresholds = [1.]\n",
    "    avg = volume.mean(dim=(2,3))\n",
    "    new_thresholds = []\n",
    "    for threshold in thresholds:\n",
    "        new_thresholds.append(threshold * avg)\n",
    "    thresholds = new_thresholds\n",
    "\n",
    "    num_features = len(thresholds) * len(windows)\n",
    "    if add_image_channel:\n",
    "        num_features += 1\n",
    "    \n",
    "    features = torch.zeros(batch_size, num_features, z, y, x, device=device)\n",
    "    cur_channel = 0\n",
    "    \n",
    "    if add_image_channel:\n",
    "        features[:, 0] = volume\n",
    "        cur_channel += 1\n",
    "\n",
    "    for t_idx, threshold in enumerate(thresholds):\n",
    "        \n",
    "        # if we want to add relative to mean thresholds\n",
    "        if isinstance(threshold, torch.Tensor):\n",
    "            threshold = threshold.view(batch_size, z, 1, 1)\n",
    "        \n",
    "        binary = volume > threshold\n",
    "        for window in windows:\n",
    "            # Add padding to binary image to calculate fractal feautures\n",
    "            pad_y = (window - (y % window)) % window\n",
    "            pad_x = (window - (x % window)) % window\n",
    "            padded_binary = F.pad(binary, (0, pad_x, 0, pad_y), value=False)\n",
    "\n",
    "            # split image into small squares to calculate fractal feautures for them\n",
    "            unfolded = padded_binary.unfold(2, window, window).unfold(3, window, window)\n",
    "            _, _, y_unf, x_unf, _, _ = unfolded.shape\n",
    "\n",
    "            # calculate fractal dimension for all squares\n",
    "            fd = fractal_dimension(\n",
    "                unfolded.reshape(batch_size*z, y_unf*x_unf, window, window)\n",
    "            ).reshape(batch_size, z, y_unf, x_unf)\n",
    "\n",
    "            # interpolate to original shape of image\n",
    "            fd_upsampled = F.interpolate(\n",
    "                fd,\n",
    "                size=(y, x),\n",
    "                mode='nearest'\n",
    "            )\n",
    "\n",
    "            features[:, cur_channel] = fd_upsampled.squeeze(1)\n",
    "            cur_channel += 1\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T11:54:50.296924Z",
     "iopub.status.busy": "2025-04-27T11:54:50.296696Z",
     "iopub.status.idle": "2025-04-27T11:54:50.313096Z",
     "shell.execute_reply": "2025-04-27T11:54:50.312450Z",
     "shell.execute_reply.started": "2025-04-27T11:54:50.296906Z"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    '''\n",
    "    UNet model without fractal features.\n",
    "    '''\n",
    "    def __init__(self, z=16, y = 256, x = 256):\n",
    "        super(UNet, self).__init__()\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # input layers\n",
    "        self.conv3d = nn.Conv3d(self.in_channels, 128, kernel_size=3, padding=1)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv3d(128, 1, kernel_size=1),\n",
    "            nn.Softmax(dim=2) # softmax over z-dimension (depth)\n",
    "        )\n",
    "\n",
    "        self.in_conv = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # contracting path\n",
    "        self.enc_conv1 = self.double_conv(128, 128)\n",
    "        self.enc_conv2 = self.double_conv(128, 256)\n",
    "        self.enc_conv3 = self.double_conv(256, 512)\n",
    "        self.enc_conv4 = self.double_conv(512, 1024)\n",
    "\n",
    "        # expansive path\n",
    "        self.up_trans1 = self.up_conv(1024, 512)\n",
    "        self.dec_conv1 = self.double_conv(1024, 512)\n",
    "        self.up_trans2 = self.up_conv(512, 256)\n",
    "        self.dec_conv2 = self.double_conv(512, 256)\n",
    "        self.up_trans3 = self.up_conv(256, 128)\n",
    "        self.dec_conv3 = self.double_conv(256, 128)\n",
    "\n",
    "        # final output\n",
    "        self.out_conv = nn.Conv2d(128, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d(x)\n",
    "        attn = self.attn(x)\n",
    "        x = torch.sum(x * attn, dim=2)\n",
    "\n",
    "        x = self.in_conv(x)\n",
    "\n",
    "        # contracting path\n",
    "        x1 = self.enc_conv1(x)\n",
    "        x2 = self.enc_conv2(F.max_pool2d(x1, kernel_size=2))\n",
    "        x3 = self.enc_conv3(F.max_pool2d(x2, kernel_size=2))\n",
    "        x4 = self.enc_conv4(F.max_pool2d(x3, kernel_size=2))\n",
    "\n",
    "        # expansive path\n",
    "        x = self.up_trans1(x4)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec_conv1(x)\n",
    "\n",
    "        x = self.up_trans2(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec_conv2(x)\n",
    "\n",
    "        x = self.up_trans3(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec_conv3(x)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def double_conv(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def up_conv(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "def initialize_weights(model):\n",
    "    '''\n",
    "    Initialize weights.\n",
    "    '''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv3d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm3d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T11:54:50.314174Z",
     "iopub.status.busy": "2025-04-27T11:54:50.313913Z",
     "iopub.status.idle": "2025-04-27T11:55:03.052139Z",
     "shell.execute_reply": "2025-04-27T11:55:03.051560Z",
     "shell.execute_reply.started": "2025-04-27T11:54:50.314149Z"
    }
   },
   "outputs": [],
   "source": [
    "train_segment_ids=[\n",
    "    20230520175435,\n",
    "    20230522181603,\n",
    "    20230522215721,\n",
    "    20230530164535,\n",
    "    20230530172803,\n",
    "    20230530212931,\n",
    "    20230531121653,\n",
    "    20230531193658,\n",
    "    20230601193301,\n",
    "    20230611014200,\n",
    "    20230620230617,\n",
    "    20230620230619,\n",
    "    20230701020044,\n",
    "    20230820203112,\n",
    "    20230826170124,\n",
    "    20230901184804,\n",
    "    20230902141231,\n",
    "    20230903193206,\n",
    "    20230904020426,\n",
    "    20230904135535,\n",
    "    20230905134255,\n",
    "    20230909121925,\n",
    "    20231001164029,\n",
    "    20231004222109,\n",
    "    20231012085431,\n",
    "    20231012184420, # big\n",
    "]\n",
    "    \n",
    "\n",
    "val_segment_id = 20230827161847\n",
    "\n",
    "tile_size = 256 \n",
    "stride = 128  # stride for moving the tile in the YX dimension\n",
    "batch_size = 4\n",
    "z_depth = 16 # thickness of the tile\n",
    "\n",
    "val_segment = Volume(val_segment_id, normalize=True)\n",
    "validation_rect = [200,5600,1000,4600] # zone with ink\n",
    "valid_dataset = VolumetricDataset(val_segment[(32 - z_depth//2):(32+z_depth//2),200:5600,1000:4600,0], val_segment.inklabel[200:5600,1000:4600]/255, tile_size, stride, validation_zone=validation_rect, valid=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T11:55:03.053078Z",
     "iopub.status.busy": "2025-04-27T11:55:03.052867Z",
     "iopub.status.idle": "2025-04-27T11:55:08.304125Z",
     "shell.execute_reply": "2025-04-27T11:55:08.303308Z",
     "shell.execute_reply.started": "2025-04-27T11:55:03.053062Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:03:34.523062Z",
     "iopub.status.busy": "2025-04-27T12:03:34.522456Z",
     "iopub.status.idle": "2025-04-27T12:03:35.025260Z",
     "shell.execute_reply": "2025-04-27T12:03:35.024206Z",
     "shell.execute_reply.started": "2025-04-27T12:03:34.523036Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(z = z_depth, y = tile_size, x = tile_size)\n",
    "initialize_weights(model)\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "NUM_EPOCHS = 50\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:25:27.099819Z",
     "iopub.status.busy": "2025-04-27T12:25:27.099145Z",
     "iopub.status.idle": "2025-04-27T12:27:06.339709Z",
     "shell.execute_reply": "2025-04-27T12:27:06.339070Z",
     "shell.execute_reply.started": "2025-04-27T12:25:27.099794Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "clip_value = 10.0\n",
    "\n",
    "scaler = GradScaler()\n",
    "model.train()\n",
    "no_improvement = 0\n",
    "best_score = 1e9\n",
    "start_time = time.time()\n",
    "logs = open(\"logs.txt\", \"w\")\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    running_loss = 0.0\n",
    "    iters = 0\n",
    "    for seg_id in train_segment_ids[:]:\n",
    "        print(f\"Epoch {epoch}, segment: {seg_id}\")\n",
    "        \n",
    "        # initialize segment at each epoch to avoid memory problems\n",
    "        segment = Volume(seg_id, normalize=True)\n",
    "        dataset = VolumetricDataset(\n",
    "            segment[(32 - z_depth//2):(32+z_depth//2),:,:,0],\n",
    "            segment.inklabel[:,:]/255, tile_size, stride,\n",
    "            validation_zone=[0,0,0,0], valid=False)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for batch_tiles, batch_labels, _ in tqdm(dataloader, position=0, leave=False):\n",
    "            batch_tiles, batch_labels = batch_tiles.to(device), batch_labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(batch_tiles)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            clip_grad_norm_(model.parameters(), clip_value)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            iters += 1\n",
    "        \n",
    "        print(f\"Loss {running_loss/iters}\")\n",
    "        segment = None\n",
    "        dataset = None\n",
    "        dataloader = None\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], running loss: {running_loss/iters}')\n",
    "    model.eval()\n",
    "    \n",
    "    val_score = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_tiles, batch_labels, corners in valid_dataloader:\n",
    "            batch_tiles, batch_labels = batch_tiles.to(device), batch_labels.float().to(device)\n",
    "    \n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(batch_tiles)\n",
    "\n",
    "            val_score += criterion(outputs, batch_labels)\n",
    "    val_score /= len(valid_dataloader)\n",
    "    print(f\"Val loss: {val_score}\")\n",
    "\n",
    "    if best_score > val_score:\n",
    "        best_score = val_score\n",
    "        torch.save(model.state_dict(), f'best_model_epoch_{epoch}_{val_score}.pth')\n",
    "    else:\n",
    "        torch.save(model.state_dict(), f'model_epoch_{epoch}_{val_score}.pth')\n",
    "    logs.write(f\"{epoch} {running_loss/iters} {val_score}\\n\")\n",
    "        \n",
    "    if running_loss/iters < 0.08 or time.time() - start_time > 18000:\n",
    "        print(f\"Final loss {running_loss/iters}\")\n",
    "        break\n",
    "print(\"Training completed.\")\n",
    "logs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:27:06.341124Z",
     "iopub.status.busy": "2025-04-27T12:27:06.340911Z",
     "iopub.status.idle": "2025-04-27T12:27:44.960976Z",
     "shell.execute_reply": "2025-04-27T12:27:44.960163Z",
     "shell.execute_reply.started": "2025-04-27T12:27:06.341107Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize predictions\n",
    "letter_predictions = np.zeros_like(val_segment.inklabel[200:5600, 1000:4600], dtype=np.float32)\n",
    "counter_predictions = np.zeros_like(val_segment.inklabel[200:5600, 1000:4600], dtype=np.float32)\n",
    "loss = 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_tiles, batch_labels, corners in valid_dataloader:\n",
    "        batch_tiles, batch_labels = batch_tiles.to(device), batch_labels.float().to(device)\n",
    "\n",
    "        with autocast(device_type=device.type):\n",
    "            outputs = model(batch_tiles)\n",
    "\n",
    "        loss += criterion(outputs, batch_labels)\n",
    "        # apply sigmoid to get probabilities from logits\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "\n",
    "        # update tiles predictions\n",
    "        corners = corners.squeeze(1).cpu().numpy()\n",
    "        for idx in range(corners.shape[0]):\n",
    "            x_start, y_start = corners[idx, 0], corners[idx, 1]\n",
    "            prediction_tile = predictions.cpu().numpy()[idx, 0] \n",
    "            letter_predictions[x_start:x_start + tile_size, y_start:y_start + tile_size] += prediction_tile\n",
    "            counter_predictions[x_start:x_start + tile_size, y_start:y_start + tile_size] += 1\n",
    "\n",
    "print(loss / len(valid_dataloader))\n",
    "\n",
    "# avoid division by zero by setting any zero counts to 1\n",
    "counter_predictions[counter_predictions == 0] = 1\n",
    "\n",
    "# normalize the predictions by the counter values\n",
    "letter_predictions /= counter_predictions\n",
    "\n",
    "# plot ground truth and model predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.imshow(val_segment.inklabel[200:5600, 1000:4600] / 255, cmap='gray')\n",
    "ax.set_title('Ground Truth Label')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.imshow(letter_predictions, cmap='gray')\n",
    "ax.set_title('Model Prediction')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig(\"final_res_UNet.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:27:44.961983Z",
     "iopub.status.busy": "2025-04-27T12:27:44.961691Z",
     "iopub.status.idle": "2025-04-27T12:27:45.151135Z",
     "shell.execute_reply": "2025-04-27T12:27:45.150574Z",
     "shell.execute_reply.started": "2025-04-27T12:27:44.961967Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'final_model_UNet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize predictions\n",
    "letter_predictions = np.zeros_like(val_segment.inklabel[200:5600, 1000:4600], dtype=np.float32)\n",
    "counter_predictions = np.zeros_like(val_segment.inklabel[200:5600, 1000:4600], dtype=np.float32)\n",
    "loss = 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_tiles, batch_labels, corners in valid_dataloader:\n",
    "        batch_tiles, batch_labels = batch_tiles.to(device), batch_labels.float().to(device)\n",
    "\n",
    "        with autocast(device_type=device.type):\n",
    "            outputs = model(batch_tiles)\n",
    "\n",
    "        loss += criterion(outputs, batch_labels)\n",
    "        # apply sigmoid to get probabilities from logits\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "\n",
    "        # update tiles predictions\n",
    "        corners = corners.squeeze(1).cpu().numpy()\n",
    "        for idx in range(corners.shape[0]):\n",
    "            x_start, y_start = corners[idx, 0], corners[idx, 1]\n",
    "            prediction_tile = predictions.cpu().numpy()[idx, 0] \n",
    "            letter_predictions[x_start:x_start + tile_size, y_start:y_start + tile_size] += prediction_tile\n",
    "            counter_predictions[x_start:x_start + tile_size, y_start:y_start + tile_size] += 1\n",
    "\n",
    "print(loss / len(valid_dataloader))\n",
    "\n",
    "# avoid division by zero by setting any zero counts to 1\n",
    "counter_predictions[counter_predictions == 0] = 1\n",
    "\n",
    "# normalize the predictions by the counter values\n",
    "letter_predictions /= counter_predictions\n",
    "\n",
    "# plot ground truth and model predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.imshow(val_segment.inklabel[200:5600, 1000:4600] / 255, cmap='gray')\n",
    "ax.set_title('Ground Truth Label')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.imshow(letter_predictions, cmap='gray')\n",
    "ax.set_title('Model Prediction')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig(\"best_res_UNet.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
