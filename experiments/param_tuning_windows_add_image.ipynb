{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003276,
     "end_time": "2025-04-28T23:46:39.857154",
     "exception": false,
     "start_time": "2025-04-28T23:46:39.853878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Финальный пайплайн обучения и теста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:46:39.863087Z",
     "iopub.status.busy": "2025-04-28T23:46:39.862830Z",
     "iopub.status.idle": "2025-04-28T23:46:51.893106Z",
     "shell.execute_reply": "2025-04-28T23:46:51.892233Z"
    },
    "papermill": {
     "duration": 12.034786,
     "end_time": "2025-04-28T23:46:51.894619",
     "exception": false,
     "start_time": "2025-04-28T23:46:39.859833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install vesuvius\n",
    "!vesuvius.accept_terms --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:46:51.902949Z",
     "iopub.status.busy": "2025-04-28T23:46:51.902724Z",
     "iopub.status.idle": "2025-04-28T23:46:56.519596Z",
     "shell.execute_reply": "2025-04-28T23:46:56.518982Z"
    },
    "papermill": {
     "duration": 4.622387,
     "end_time": "2025-04-28T23:46:56.520896",
     "exception": false,
     "start_time": "2025-04-28T23:46:51.898509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vesuvius\n",
    "from vesuvius import Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:46:56.533673Z",
     "iopub.status.busy": "2025-04-28T23:46:56.532961Z",
     "iopub.status.idle": "2025-04-28T23:47:00.170588Z",
     "shell.execute_reply": "2025-04-28T23:47:00.169808Z"
    },
    "papermill": {
     "duration": 3.647834,
     "end_time": "2025-04-28T23:47:00.172376",
     "exception": false,
     "start_time": "2025-04-28T23:46:56.524542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:47:00.180930Z",
     "iopub.status.busy": "2025-04-28T23:47:00.180561Z",
     "iopub.status.idle": "2025-04-28T23:47:00.189996Z",
     "shell.execute_reply": "2025-04-28T23:47:00.189512Z"
    },
    "papermill": {
     "duration": 0.014886,
     "end_time": "2025-04-28T23:47:00.191095",
     "exception": false,
     "start_time": "2025-04-28T23:47:00.176209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VolumetricDataset(Dataset):\n",
    "    def __init__(self, volume, label, tile_size, stride, validation_zone, valid=False):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with the volume and label.\n",
    "        \n",
    "        volume (np.ndarray): The volumetric image of shape (Z, Y, X).\n",
    "        label (np.ndarray): The 2D label of shape (Y, X).\n",
    "        tile_size (int): The size of the tiles to extract along the Y and X dimensions.\n",
    "        stride (int): The stride for extracting tiles along the Y and X dimensions.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.volume = volume\n",
    "        self.label = label\n",
    "        self.tile_size = tile_size\n",
    "        self.stride = stride\n",
    "        self.validation_zone = validation_zone\n",
    "        self.valid = valid\n",
    "        self.tiles, self.labels, self.corners = self.extract_tiles()\n",
    "\n",
    "    def extract_tiles(self):\n",
    "        \"\"\"\n",
    "        Extract 3D tiles from the volume and corresponding 2D labels.\n",
    "\n",
    "        Returns:\n",
    "            tiles (list): A list of 3D tiles.\n",
    "            labels (list): A list of 2D labels.\n",
    "        \"\"\"\n",
    "        Z, Y, X = self.volume.shape\n",
    "        tiles = []\n",
    "        labels = []\n",
    "        corners = []\n",
    "        # generate 3D tiles by moving along the Y and X axes\n",
    "        for y in range(0, Y - self.tile_size + 1, self.stride):\n",
    "            for x in range(0, X - self.tile_size + 1, self.stride):\n",
    "                if self.valid is False:\n",
    "                    if (y + self.tile_size < self.validation_zone[0]) or (y > self.validation_zone[1]):\n",
    "                        if (x + self.tile_size < self.validation_zone[2]) or (x > self.validation_zone[3]):\n",
    "                            tile = self.volume[:, y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            label_tile = self.label[y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            if np.sum(label_tile)/self.tile_size**2 > 0.05: # at least 5% of ink\n",
    "                                tiles.append(tile)\n",
    "                                labels.append(label_tile)\n",
    "                                corners.append([y,x])\n",
    "                else:\n",
    "                    if (y >= self.validation_zone[0]) and (y + self.tile_size <= self.validation_zone[1]):\n",
    "                        if (x >= self.validation_zone[2]) and (x + self.tile_size <= self.validation_zone[3]):\n",
    "                            tile = self.volume[:, y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            label_tile = self.label[y:y + self.tile_size, x:x + self.tile_size]\n",
    "                            tiles.append(tile)\n",
    "                            labels.append(label_tile)\n",
    "                            corners.append([y,x])\n",
    "\n",
    "        return tiles, labels, corners\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tile = self.tiles[idx] \n",
    "        label = self.labels[idx]\n",
    "        corners = self.corners[idx]\n",
    "        \n",
    "        tile = torch.tensor(tile, dtype=torch.float32).unsqueeze(0)\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "        corners = torch.tensor(corners, dtype=torch.int).unsqueeze(0)\n",
    "        return tile, label, corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:47:00.198528Z",
     "iopub.status.busy": "2025-04-28T23:47:00.198337Z",
     "iopub.status.idle": "2025-04-28T23:47:00.210039Z",
     "shell.execute_reply": "2025-04-28T23:47:00.209345Z"
    },
    "papermill": {
     "duration": 0.016748,
     "end_time": "2025-04-28T23:47:00.211076",
     "exception": false,
     "start_time": "2025-04-28T23:47:00.194328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fractal_dimension(binary):\n",
    "    '''\n",
    "    Calculate fractal dimension of binary image ln(N) / ln(1/r) using box counting method.\n",
    "    '''\n",
    "    device = binary.device\n",
    "    batch_size, blocks_num, height, width = binary.shape\n",
    "    min_dim = min(height, width)\n",
    "    # square sizes to use box counting method\n",
    "    scales = torch.tensor([1,2,4,6,8,10], device=device)\n",
    "    scales = torch.unique(scales)\n",
    "    scales = scales[scales <= min_dim]\n",
    "    counts = []\n",
    "\n",
    "    binary_flat = binary.view(-1, height, width)\n",
    "    cnt_flat = binary_flat.size(0)\n",
    "    for scale in scales:\n",
    "        if scale < 1:\n",
    "            continue\n",
    "\n",
    "        # add zero padding to use box counting method\n",
    "        pad_h = (scale - (height % scale)) % scale\n",
    "        pad_w = (scale - (width % scale)) % scale\n",
    "        padded_binary = F.pad(binary_flat, (0, pad_w, 0, pad_h), value=False)\n",
    "\n",
    "        # split image into small squares to use box counting method\n",
    "        unfolded = padded_binary.unfold(1, scale, scale).unfold(2, scale, scale)\n",
    "        count = unfolded.any(dim=-1).any(dim=-1).sum(dim=(1,2))\n",
    "        counts.append(count)\n",
    "\n",
    "    if len(counts) < 2:\n",
    "        return torch.zeros(batch_size, blocks_num, device=device)\n",
    "    \n",
    "    log_scales = torch.log(1 / scales.float() + 1e-8) # log(1/r)\n",
    "    log_counts = torch.log(torch.stack(counts, dim=1).float() + 1e-8) # log(N)\n",
    "\n",
    "    # here we prepare matricies to get the slope of the line that best fits the\n",
    "    # 2D points of the form (ln(N), ln(1/r))\n",
    "    # that way we will get fractal dimensions\n",
    "    X = torch.stack([log_scales, torch.ones_like(log_scales)], dim=1) \n",
    "    X = X.repeat(cnt_flat, 1, 1)\n",
    "    Y = log_counts.unsqueeze(-1)\n",
    "\n",
    "    # get the slope of the line that best fits the 2D points of the form (ln(N), ln(1/r)) \n",
    "    coeffs = torch.linalg.lstsq(X, Y).solution.squeeze(-1)\n",
    "\n",
    "    # FD is first coefficient (slope of the line)\n",
    "    fd = coeffs[..., 0]\n",
    "    return fd\n",
    "\n",
    "\n",
    "def calc_fractal_features(input_volume, windows = [2,4,8], thresholds=None, absolute=True, add_image_channel = False):\n",
    "    '''\n",
    "    Calculate fractal features of image with certain sizes of window \n",
    "    and certain thresholds to make image binary (binary = (image > image.mean() * threshold)).\n",
    "\n",
    "    Also we could add original image to those features.\n",
    "    '''\n",
    "    device = input_volume.device\n",
    "    batch_size, channels, z, y, x = input_volume.shape # channels = 1\n",
    "\n",
    "    volume = input_volume.view(batch_size*channels, z, y, x)\n",
    "\n",
    "    max_window_size = min(y, x) // 2\n",
    "    windows = torch.tensor(windows, device=device)\n",
    "    windows = windows[windows <= max_window_size]\n",
    "\n",
    "    if thresholds is None:\n",
    "        thresholds = [1.]\n",
    "        absolute = False\n",
    "    if not absolute:\n",
    "        avg = volume.mean(dim=(2,3))\n",
    "        new_thresholds = []\n",
    "        for threshold in thresholds:\n",
    "            new_thresholds.append(threshold * avg)\n",
    "        thresholds = new_thresholds\n",
    "\n",
    "    num_features = len(thresholds) * len(windows)\n",
    "    if add_image_channel:\n",
    "        num_features += 1\n",
    "    \n",
    "    features = torch.zeros(batch_size, num_features, z, y, x, device=device)\n",
    "    cur_channel = 0\n",
    "    \n",
    "    if add_image_channel:\n",
    "        features[:, 0] = volume\n",
    "        cur_channel += 1\n",
    "\n",
    "    for t_idx, threshold in enumerate(thresholds):\n",
    "        \n",
    "        # if we want to add relative to mean thresholds\n",
    "        if isinstance(threshold, torch.Tensor):\n",
    "            threshold = threshold.view(batch_size, z, 1, 1)\n",
    "        \n",
    "        binary = volume > threshold\n",
    "        for window in windows:\n",
    "            # Add padding to binary image to calculate fractal feautures\n",
    "            pad_y = (window - (y % window)) % window\n",
    "            pad_x = (window - (x % window)) % window\n",
    "            padded_binary = F.pad(binary, (0, pad_x, 0, pad_y), value=False)\n",
    "\n",
    "            # split image into small squares to calculate fractal feautures for them\n",
    "            unfolded = padded_binary.unfold(2, window, window).unfold(3, window, window)\n",
    "            _, _, y_unf, x_unf, _, _ = unfolded.shape\n",
    "\n",
    "            # calculate fractal dimension for all squares\n",
    "            fd = fractal_dimension(\n",
    "                unfolded.reshape(batch_size*z, y_unf*x_unf, window, window)\n",
    "            ).reshape(batch_size, z, y_unf, x_unf)\n",
    "\n",
    "            # interpolate to original shape of image\n",
    "            fd_upsampled = F.interpolate(\n",
    "                fd,\n",
    "                size=(y, x),\n",
    "                mode='nearest'\n",
    "            )\n",
    "\n",
    "            features[:, cur_channel] = fd_upsampled.squeeze(1)\n",
    "            cur_channel += 1\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:47:00.218310Z",
     "iopub.status.busy": "2025-04-28T23:47:00.218105Z",
     "iopub.status.idle": "2025-04-28T23:47:00.229537Z",
     "shell.execute_reply": "2025-04-28T23:47:00.228876Z"
    },
    "papermill": {
     "duration": 0.016247,
     "end_time": "2025-04-28T23:47:00.230524",
     "exception": false,
     "start_time": "2025-04-28T23:47:00.214277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet_with_FF(nn.Module):\n",
    "    def __init__(self, z=16, y = 256, x = 256, windows = [2,4,8,16], thresholds=None, add_image_channel = False):\n",
    "        super().__init__()\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.windows = windows\n",
    "        self.thresholds = thresholds\n",
    "        threshold_num = 1 if thresholds is None else len(thresholds)\n",
    "        in_channels = len(windows) * threshold_num\n",
    "        if add_image_channel:\n",
    "            in_channels += 1\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # input layers\n",
    "        self.conv3d = nn.Conv3d(self.in_channels, 128, kernel_size=3, padding=1)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv3d(128, 1, kernel_size=1),\n",
    "            nn.Softmax(dim=2) # softmax over z-dimension (depth)\n",
    "        )\n",
    "\n",
    "        self.in_conv = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # contracting path\n",
    "        self.enc_conv1 = self.double_conv(128, 128)\n",
    "        self.enc_conv2 = self.double_conv(128, 256)\n",
    "        self.enc_conv3 = self.double_conv(256, 512)\n",
    "        self.enc_conv4 = self.double_conv(512, 1024)\n",
    "\n",
    "        # expansive path\n",
    "        self.up_trans1 = self.up_conv(1024, 512)\n",
    "        self.dec_conv1 = self.double_conv(1024, 512)\n",
    "        self.up_trans2 = self.up_conv(512, 256)\n",
    "        self.dec_conv2 = self.double_conv(512, 256)\n",
    "        self.up_trans3 = self.up_conv(256, 128)\n",
    "        self.dec_conv3 = self.double_conv(256, 128)\n",
    "\n",
    "        # final output\n",
    "        self.out_conv = nn.Conv2d(128, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3d(x)\n",
    "        attn = self.attn(x)\n",
    "        x = torch.sum(x * attn, dim=2)\n",
    "\n",
    "        x = self.in_conv(x)\n",
    "\n",
    "        # contracting path\n",
    "        x1 = self.enc_conv1(x)\n",
    "        x2 = self.enc_conv2(F.max_pool2d(x1, kernel_size=2))\n",
    "        x3 = self.enc_conv3(F.max_pool2d(x2, kernel_size=2))\n",
    "        x4 = self.enc_conv4(F.max_pool2d(x3, kernel_size=2))\n",
    "\n",
    "        # expansive path\n",
    "        x = self.up_trans1(x4)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec_conv1(x)\n",
    "\n",
    "        x = self.up_trans2(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec_conv2(x)\n",
    "\n",
    "        x = self.up_trans3(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec_conv3(x)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def double_conv(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def up_conv(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    '''\n",
    "    Initialize weights.\n",
    "    '''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv3d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm3d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:47:00.237803Z",
     "iopub.status.busy": "2025-04-28T23:47:00.237612Z",
     "iopub.status.idle": "2025-04-28T23:47:09.338540Z",
     "shell.execute_reply": "2025-04-28T23:47:09.337835Z"
    },
    "papermill": {
     "duration": 9.106049,
     "end_time": "2025-04-28T23:47:09.339871",
     "exception": false,
     "start_time": "2025-04-28T23:47:00.233822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "segment_id = 20230827161847\n",
    "\n",
    "tile_size = 256 \n",
    "stride = 128  # stride for moving the tile in the YX dimension\n",
    "batch_size = 4\n",
    "z_depth = 16 # thickness of the tile\n",
    "\n",
    "segment = Volume(segment_id, normalize=True)\n",
    "validation_rect = [3260, 3260+512, 1860, 1860+512]\n",
    "\n",
    "valid_dataset = VolumetricDataset(segment[(32 - z_depth//2):(32+z_depth//2),200:5600,1000:4600,0], segment.inklabel[200:5600,1000:4600]/255, tile_size, stride, validation_zone=validation_rect, valid=True)\n",
    "train_dataset = VolumetricDataset(segment[(32 - z_depth//2):(32+z_depth//2),200:5600,1000:4600,0], segment.inklabel[200:5600,1000:4600]/255, tile_size, stride, validation_zone=validation_rect, valid=False)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:07:13.110013Z",
     "iopub.status.busy": "2025-04-29T03:07:13.109708Z",
     "iopub.status.idle": "2025-04-29T03:07:13.127825Z",
     "shell.execute_reply": "2025-04-29T03:07:13.127061Z",
     "shell.execute_reply.started": "2025-04-29T03:07:13.109973Z"
    },
    "papermill": {
     "duration": 0.01259,
     "end_time": "2025-04-28T23:47:09.356241",
     "exception": false,
     "start_time": "2025-04-28T23:47:09.343651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def get_random_thresholds(k, min_val=0.05, max_val=0.55, step=0.05):\n",
    "    ans = []\n",
    "    while len(ans) < k:\n",
    "        possible_values = np.arange(min_val, max_val, step).tolist()\n",
    "        n = random.randint(1, 5)\n",
    "        random_numbers = sorted(random.sample(possible_values, k=n))\n",
    "        if random_numbers not in ans:\n",
    "            ans.append(random_numbers)\n",
    "    return ans\n",
    "\n",
    "def get_random_windows(k, tile_size=256):\n",
    "    ans = []\n",
    "    while len(ans) < k:\n",
    "        possible_values = [2]\n",
    "        while possible_values[-1] < tile_size//2:\n",
    "            possible_values.append(possible_values[-1] * 2)\n",
    "        n = random.randint(1, 7)\n",
    "        random_numbers = sorted(random.sample(possible_values, k=n))\n",
    "        if random_numbers not in ans:\n",
    "            ans.append(random_numbers)\n",
    "    return ans\n",
    "\n",
    "abs_thresholds_search = [[0.05, 0.2, 0.35000000000000003]]\n",
    "relative_thresholds_search = [[0.5, 1.75, 2.25]]\n",
    "widndows_search = [\n",
    "    [2,4,8,16,32,64,128],\n",
    "    [2,4,8,16,32,64],\n",
    "    [2,4,8,16,32],\n",
    "    [2,4,8,16],\n",
    "    [2,4,8],\n",
    "    [2,4],\n",
    "    [2, 8, 32, 128],\n",
    "    [2, 16, 128],\n",
    "    [2, 128],\n",
    "    [4,16,128]\n",
    "]\n",
    "print(abs_thresholds_search, relative_thresholds_search, \"\\n\", widndows_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:47:09.363760Z",
     "iopub.status.busy": "2025-04-28T23:47:09.363562Z",
     "iopub.status.idle": "2025-04-29T01:13:09.347926Z",
     "shell.execute_reply": "2025-04-29T01:13:09.347177Z"
    },
    "papermill": {
     "duration": 5159.989561,
     "end_time": "2025-04-29T01:13:09.349213",
     "exception": false,
     "start_time": "2025-04-28T23:47:09.359652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "clip_value = 10.0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCHS = 50\n",
    "logs = open(\"logs.txt\", \"w\")\n",
    "start_time = time.time()\n",
    "early_stopping = 4\n",
    "            \n",
    "for thresholds in abs_thresholds_search:\n",
    "    for windows in widndows_search:\n",
    "        for add_image_channel in [False, True]:\n",
    "            print(f\"Model windows={windows}, thresholds={thresholds}, abs=True, add_image_channel={add_image_channel}\")\n",
    "            logs.write(f\"Model {windows} {thresholds} {add_image_channel}\\n\")\n",
    "            model = UNet_with_FF(z=z_depth, y=tile_size, x=tile_size,\n",
    "                        windows=windows, thresholds=thresholds, add_image_channel=add_image_channel)\n",
    "            initialize_weights(model)\n",
    "            model = model.to(device)\n",
    "            criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "            scaler = GradScaler()\n",
    "            model.train()\n",
    "            no_improvement = 0\n",
    "            best_score = 1e9\n",
    "            \n",
    "            for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "                running_loss = 0.0\n",
    "                    \n",
    "                model.train()\n",
    "            \n",
    "                for batch_tiles, batch_labels, _ in tqdm(dataloader, position=0, leave=False):\n",
    "                    batch_tiles, batch_labels = batch_tiles.to(device), batch_labels.float().to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    with autocast(device_type=device.type):\n",
    "                        outputs = calc_fractal_features(batch_tiles,\n",
    "                                                        windows = windows,\n",
    "                                                        thresholds = thresholds,\n",
    "                                                        absolute = True,\n",
    "                                                        add_image_channel = add_image_channel)\n",
    "                        outputs = model(outputs)\n",
    "                        loss = criterion(outputs, batch_labels)\n",
    "        \n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    clip_grad_norm_(model.parameters(), clip_value)\n",
    "        \n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    \n",
    "                    running_loss += loss.item()\n",
    "                \n",
    "                print(f\"Loss {running_loss/len(dataloader)}\")\n",
    "                    \n",
    "                scheduler.step()\n",
    "                \n",
    "                print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], running loss: {running_loss/len(dataloader)}')\n",
    "\n",
    "                letter_predictions = np.zeros_like(segment.inklabel[200:5600, 1000:4600], dtype=np.float32)\n",
    "                counter_predictions = np.zeros_like(segment.inklabel[200:5600, 1000:4600], dtype=np.float32)\n",
    "                val_loss = 0.0\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for batch_tiles, batch_labels, corners in valid_dataloader:\n",
    "                        batch_tiles, batch_labels = batch_tiles.to(device), batch_labels.float().to(device)\n",
    "                \n",
    "                        with autocast(device_type=device.type):\n",
    "                            outputs = calc_fractal_features(batch_tiles,\n",
    "                                                                windows = windows,\n",
    "                                                                thresholds = thresholds,\n",
    "                                                                absolute = True,\n",
    "                                                                add_image_channel = add_image_channel)\n",
    "                            outputs = model(outputs)\n",
    "\n",
    "                            val_loss += criterion(outputs, batch_labels)\n",
    "                            # apply sigmoid to get probabilities from logits\n",
    "                            predictions = torch.sigmoid(outputs)\n",
    "\n",
    "                            # update tiles predictions\n",
    "                            corners = corners.squeeze(1).cpu().numpy()\n",
    "                            for idx in range(corners.shape[0]):\n",
    "                                x_start, y_start = corners[idx, 0], corners[idx, 1]\n",
    "                                prediction_tile = predictions.cpu().numpy()[idx, 0] \n",
    "                                letter_predictions[x_start:x_start + tile_size, y_start:y_start + tile_size] += prediction_tile\n",
    "                                counter_predictions[x_start:x_start + tile_size, y_start:y_start + tile_size] += 1\n",
    "\n",
    "                val_loss /= len(valid_dataloader)\n",
    "                print(\"Val Loss:\", val_loss)\n",
    "\n",
    "                # avoid division by zero by setting any zero counts to 1\n",
    "                counter_predictions[counter_predictions == 0] = 1\n",
    "                \n",
    "                # normalize the predictions by the counter values\n",
    "                letter_predictions /= counter_predictions\n",
    "            \n",
    "                if best_score > val_loss:\n",
    "                    no_improvement = 0\n",
    "                    best_score = val_loss\n",
    "                    torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()},\n",
    "                               f'best_model_windows_{windows}_thresholds_{thresholds}_image_{add_image_channel}_epoch_{epoch}_{val_loss}.pth')\n",
    "                else:\n",
    "                    no_improvement += 1\n",
    "                \n",
    "                logs.write(f\"{epoch} {running_loss/len(dataloader)} {val_loss}\\n\")\n",
    "                    \n",
    "                if running_loss/len(dataloader) < 0.08 or time.time() - start_time > 18000 or no_improvement > 6:\n",
    "                    print(f\"Final loss {running_loss/len(dataloader)}\")\n",
    "                     # plot ground truth and model predictions\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "                    \n",
    "                    ax = axes[0]\n",
    "                    ax.imshow(segment.inklabel[200:5600, 1000:4600] / 255, cmap='gray')\n",
    "                    ax.set_title('Ground Truth Label')\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "                    ax = axes[1]\n",
    "                    ax.imshow(letter_predictions, cmap='gray')\n",
    "                    ax.set_title('Model Prediction')\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "                    plt.savefig(f\"Model windows={windows}, thresholds={thresholds}, add_image_channel={add_image_channel}.png\")\n",
    "                    torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()},\n",
    "                               f'final_model_windows_{windows}_thresholds_{thresholds}_image_{add_image_channel}_{val_loss}.pth')\n",
    "                    break\n",
    "print(\"Training completed.\")\n",
    "\n",
    "logs.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.477915,
     "end_time": "2025-04-29T02:46:05.853519",
     "exception": false,
     "start_time": "2025-04-29T02:46:05.375604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 321616,
     "modelInstanceId": 301082,
     "sourceId": 362483,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10773.75225,
   "end_time": "2025-04-29T02:46:09.571730",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-28T23:46:35.819480",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
